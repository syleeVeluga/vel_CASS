"""
CASS Lite â€” ë²”ì£„ë¶„ì„ ì„ ë³„ ì‹œìŠ¤í…œ (ê²½ëŸ‰í™” ë²„ì „)
PDF ì¡°ì„œ â†’ ë¬¸ë‹µ íŒŒì‹± â†’ AI 2ë‹¨ê³„ ê²€ì¦ â†’ ì²´í¬ë¦¬ìŠ¤íŠ¸ í†µí•© ë¦¬í¬íŠ¸
"""

import json
import os
import streamlit as st
import pandas as pd
from dotenv import load_dotenv, dotenv_values
from pathlib import Path

from parsing.pdf_parser import extract_text, parse_qa, save_csv
from analysis.chunker import create_chunks
from analysis.llm_utils import (
    LLMConfig,
    AVAILABLE_MODELS,
    REASONING_LEVELS,
    call_analyst,
    call_critic,
    call_reporter,
)

# .env íŒŒì¼ ê²½ë¡œ (app.py ê¸°ì¤€)
_ENV_PATH = Path(__file__).parent / ".env"


def init_page():
    """í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •."""
    st.set_page_config(
        page_title="CASS Lite â€” ë²”ì£„ë¶„ì„ ì„ ë³„ ì‹œìŠ¤í…œ",
        page_icon="ğŸ”",
        layout="wide",
        initial_sidebar_state="expanded",
    )


def setup_sidebar() -> LLMConfig | None:
    """
    ì‚¬ì´ë“œë°”: í”„ë¡œë°”ì´ë”, ëª¨ë¸, Reasoning ë ˆë²¨, API Key ì„¤ì •.
    Returns LLMConfig or None if not configured.
    """
    st.sidebar.title("âš™ï¸ AI ì„¤ì •")
    st.sidebar.divider()

    # í”„ë¡œë°”ì´ë” ì„ íƒ
    provider = st.sidebar.selectbox(
        "LLM í”„ë¡œë°”ì´ë”",
        options=list(AVAILABLE_MODELS.keys()),
        help="ë¶„ì„ì— ì‚¬ìš©í•  AI ëª¨ë¸ í”„ë¡œë°”ì´ë”ë¥¼ ì„ íƒí•˜ì„¸ìš”.",
    )

    # ëª¨ë¸ ì„ íƒ
    model_options = AVAILABLE_MODELS[provider]
    model_label = st.sidebar.selectbox(
        "ëª¨ë¸",
        options=list(model_options.keys()),
    )
    model_id = model_options[model_label]

    # Reasoning ë ˆë²¨ ì„ íƒ
    if provider == "OpenAI":
        reasoning_options = REASONING_LEVELS["OpenAI"]
    else:
        reasoning_options = REASONING_LEVELS["Gemini"].get(model_id, ["low", "high"])

    reasoning_level = st.sidebar.select_slider(
        "Reasoning ë ˆë²¨",
        options=reasoning_options,
        value=reasoning_options[len(reasoning_options) // 2],  # ì¤‘ê°„ê°’ ê¸°ë³¸
        help="ë†’ì„ìˆ˜ë¡ ê¹Šì´ ì‚¬ê³ í•˜ì§€ë§Œ ì‘ë‹µì´ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )

    st.sidebar.divider()

    # â”€â”€ API Key ë³´ì•ˆ ì²˜ë¦¬ â”€â”€
    # ë§¤ë²ˆ .env íŒŒì¼ì„ ë‹¤ì‹œ ì½ì–´ ìµœì‹  í‚¤ë¥¼ ë°˜ì˜ (ì„œë²„ ì¬ì‹œì‘ ë¶ˆí•„ìš”)
    load_dotenv(_ENV_PATH, override=True)
    env_key_name = "OPENAI_API_KEY" if provider == "OpenAI" else "GOOGLE_API_KEY"

    # .env íŒŒì¼ì—ì„œ ì§ì ‘ ì½ê¸° (os.getenvê°€ ë¹ˆ ë¬¸ìì—´ì„ ë°˜í™˜í•˜ëŠ” ê²½ìš° ëŒ€ë¹„)
    env_values = dotenv_values(_ENV_PATH)
    env_key = (env_values.get(env_key_name) or "").strip()
    if not env_key:
        # ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ fallback
        env_key = (os.getenv(env_key_name) or "").strip()
    has_env_key = bool(env_key)

    api_key = ""

    if has_env_key:
        # .envì— í‚¤ê°€ ìˆìœ¼ë©´ ì¡´ì¬ ì—¬ë¶€ë§Œ í‘œì‹œ (ê°’ì€ ì ˆëŒ€ ë…¸ì¶œ ì•ˆ í•¨)
        st.sidebar.success(
            f"ğŸ” **{env_key_name}** â€” .envì—ì„œ ë¡œë“œë¨\n\n"
            f"í‚¤ê°€ ì•ˆì „í•˜ê²Œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
            icon="âœ…",
        )
        api_key = env_key  # ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì‚¬ìš©
    else:
        # .envì— í‚¤ê°€ ì—†ìœ¼ë©´ ìˆ˜ë™ ì…ë ¥ í—ˆìš© (password íƒ€ì…)
        st.sidebar.info(
            f"ğŸ“ .envì— `{env_key_name}`ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
            f"ì•„ë˜ì—ì„œ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.",
            icon="â„¹ï¸",
        )
        manual_key = st.sidebar.text_input(
            f"ğŸ”‘ {provider} API Key ì…ë ¥",
            value="",
            type="password",
            placeholder="API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
            help="ì…ë ¥ëœ í‚¤ëŠ” í˜„ì¬ ì„¸ì…˜ì—ì„œë§Œ ì‚¬ìš©ë˜ë©° ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
        )
        api_key = manual_key.strip()

    # ì„¤ì • ìš”ì•½
    st.sidebar.divider()
    st.sidebar.caption("ğŸ“‹ í˜„ì¬ ì„¤ì •")

    if api_key:
        key_source = "ğŸ” .env" if has_env_key else "ğŸ”‘ ìˆ˜ë™ì…ë ¥"
        key_status = f"âœ… ì‚¬ìš© ê°€ëŠ¥ ({key_source})"
    else:
        key_status = "âŒ ë¯¸ì„¤ì •"

    st.sidebar.code(
        f"Provider: {provider}\n"
        f"Model: {model_label}\n"
        f"Reasoning: {reasoning_level}\n"
        f"API Key: {key_status}",
        language=None,
    )

    if not api_key:
        return None

    return LLMConfig(
        provider=provider,
        api_key=api_key,
        model=model_id,
        reasoning_level=reasoning_level,
    )


def section_upload():
    """ì„¹ì…˜ 1: ì¡°ì„œ PDF ì—…ë¡œë“œ ë° íŒŒì‹±."""
    st.header("ğŸ“„ 1. ì¡°ì„œ ì—…ë¡œë“œ", divider="blue")

    uploaded_file = st.file_uploader(
        "ìˆ˜ì‚¬ ì¡°ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=["pdf"],
        help="ì§€ì› í˜•ì‹: PDF (í”¼ì˜ì ì‹ ë¬¸ì¡°ì„œ, ì§„ìˆ ì¡°ì„œ ë“±)",
    )

    if uploaded_file is not None:
        if (
            "uploaded_filename" not in st.session_state
            or st.session_state.uploaded_filename != uploaded_file.name
        ):
            with st.status("ğŸ“„ PDF íŒŒì‹± ì¤‘...", expanded=True) as status:
                st.write("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
                raw_text = extract_text(uploaded_file)
                st.session_state.raw_text = raw_text

                st.write("ë¬¸ë‹µ(Q&A) êµ¬ì¡°í™” ì¤‘...")
                parsed_df = parse_qa(raw_text)
                st.session_state.parsed_df = parsed_df
                st.session_state.uploaded_filename = uploaded_file.name

                st.write(f"âœ… ì´ {len(parsed_df)}ê°œ ë¬¸ë‹µ ì¶”ì¶œ ì™„ë£Œ")
                status.update(label="íŒŒì‹± ì™„ë£Œ!", state="complete", expanded=False)

        st.success(
            f"ğŸ“‚ **{uploaded_file.name}** â€” "
            f"{len(st.session_state.parsed_df)}ê°œ ë¬¸ë‹µ ì¶”ì¶œë¨"
        )

    return uploaded_file is not None and "parsed_df" in st.session_state


def section_review():
    """ì„¹ì…˜ 2: íŒŒì‹± ë°ì´í„° í™•ì¸ ë° ìˆ˜ì •."""
    st.header("ğŸ“ 2. ë°ì´í„° í™•ì¸ ë° ìˆ˜ì •", divider="orange")

    if "parsed_df" not in st.session_state:
        st.info("ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        return False

    st.caption(
        "ğŸ’¡ ì•„ë˜ í‘œì—ì„œ ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
        "ì •ê·œì‹ì´ ë†“ì¹œ ë¬¸ë‹µ ë¶„ë¦¬ë¥¼ ìˆ˜ì •í•˜ë©´ ë¶„ì„ ì •í™•ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤."
    )

    edited_df = st.data_editor(
        st.session_state.parsed_df,
        num_rows="dynamic",
        use_container_width=True,
        column_config={
            "index": st.column_config.NumberColumn("ë²ˆí˜¸", width="small"),
            "type": st.column_config.SelectboxColumn(
                "ìœ í˜•", options=["Q", "A"], width="small"
            ),
            "speaker": st.column_config.SelectboxColumn(
                "í™”ì", options=["ìˆ˜ì‚¬ê´€", "í”¼ì˜ì"], width="small"
            ),
            "content": st.column_config.TextColumn("ë‚´ìš©", width="large"),
        },
        key="data_editor",
    )

    # ìˆ˜ì •ëœ ë°ì´í„°ë¥¼ ì„¸ì…˜ì— ë°˜ì˜
    st.session_state.edited_df = edited_df

    # CSV ì €ì¥ ë²„íŠ¼ (ë‹¤ìš´ë¡œë“œ í´ë”ë¡œ ì €ì¥)
    col1, col2 = st.columns([1, 5])
    with col1:
        if st.button("ğŸ’¾ CSV ì €ì¥", use_container_width=True):
            saved_path = save_csv(edited_df)
            st.toast(f"âœ… ë‹¤ìš´ë¡œë“œ í´ë”ì— ì €ì¥ ì™„ë£Œ!\n{saved_path}", icon="ğŸ’¾")

    with col2:
        st.caption(f"ì´ {len(edited_df)}ê°œ í–‰ | ğŸ“ ë‹¤ìš´ë¡œë“œ í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤")

    return len(edited_df) > 0


def section_analysis(config: LLMConfig | None):
    """ì„¹ì…˜ 3: AI ë¶„ì„ ì‹¤í–‰ ë° ê²°ê³¼."""
    st.header("ğŸ” 3. AI ë¶„ì„ ê²°ê³¼", divider="red")

    if config is None:
        st.warning("âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ API Keyë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return

    if "edited_df" not in st.session_state:
        st.info("ë¨¼ì € ë°ì´í„° í™•ì¸ ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")
        return

    df = st.session_state.edited_df

    # ë¶„ì„ ì‹œì‘ ë²„íŠ¼
    if st.button("â–¶ï¸ ë¶„ì„ ë° ì„ ë³„ ì‹œì‘", type="primary", use_container_width=True):
        _run_analysis(df, config)

    # ì´ì „ ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
    if "final_report" in st.session_state:
        st.divider()
        st.markdown(st.session_state.final_report)

        # ë¶„ì„ ë¡œê·¸
        if "analysis_log" in st.session_state:
            with st.expander("ğŸ“‹ ë¶„ì„ ë¡œê·¸ ìƒì„¸ ë³´ê¸°"):
                for log_entry in st.session_state.analysis_log:
                    st.markdown(log_entry)


def _run_analysis(df: pd.DataFrame, config: LLMConfig):
    """ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (Analyst â†’ Critic â†’ Reporter)."""
    chunks = create_chunks(df, size=20, overlap=3)
    total_chunks = len(chunks)

    if total_chunks == 0:
        st.error("ë¶„ì„í•  ë¬¸ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    all_verified = []
    analysis_log = []
    total_rejected = 0

    progress_bar = st.progress(0, text="ë¶„ì„ ì¤€ë¹„ ì¤‘...")

    with st.status(f"ğŸ”„ ì´ {total_chunks}ê°œ ì²­í¬ ë¶„ì„ ì¤‘...", expanded=True) as status:
        for i, chunk in enumerate(chunks):
            chunk_label = f"[ì²­í¬ {i + 1}/{total_chunks}]"

            # â”€â”€ Step A: Analyst â”€â”€
            st.write(f"{chunk_label} ğŸ” ë¶„ì„ ì¤‘...")
            try:
                draft = call_analyst(chunk, config)
                finding_count = sum(
                    len(draft.get(k, []))
                    for k in ["admissions", "contradictions", "alibis", "suspicious_indicators"]
                )
                st.write(f"{chunk_label} â†’ {finding_count}ê±´ ë°œê²¬")
                analysis_log.append(
                    f"**{chunk_label}** Analyst: {finding_count}ê±´ ì¶”ì¶œ"
                )
            except Exception as e:
                st.error(f"{chunk_label} Analyst ì˜¤ë¥˜: {e}")
                analysis_log.append(f"**{chunk_label}** âŒ Analyst ì˜¤ë¥˜: {e}")
                continue

            # â”€â”€ Step B: Critic â”€â”€
            st.write(f"{chunk_label} âœ… ê²€ì¦ ì¤‘...")
            try:
                verified = call_critic(chunk, draft, config)
                verified_count = len(verified.get("verified_findings", []))
                rejected_count = len(verified.get("rejected_findings", []))
                total_rejected += rejected_count

                st.write(
                    f"{chunk_label} â†’ {verified_count}ê±´ í†µê³¼, "
                    f"{rejected_count}ê±´ ê¸°ê°"
                )
                analysis_log.append(
                    f"**{chunk_label}** Critic: âœ… {verified_count}ê±´ í†µê³¼ / "
                    f"âŒ {rejected_count}ê±´ ê¸°ê°"
                )

                if verified.get("verified_findings"):
                    all_verified.extend(verified["verified_findings"])
            except Exception as e:
                st.error(f"{chunk_label} Critic ì˜¤ë¥˜: {e}")
                analysis_log.append(f"**{chunk_label}** âŒ Critic ì˜¤ë¥˜: {e}")
                continue

            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress_bar.progress(
                (i + 1) / total_chunks,
                text=f"{chunk_label} ì™„ë£Œ ({i + 1}/{total_chunks})",
            )

        status.update(
            label=f"âœ… ë¶„ì„ ì™„ë£Œ â€” {len(all_verified)}ê±´ ê²€ì¦ í†µê³¼, {total_rejected}ê±´ ê¸°ê°",
            state="complete",
            expanded=False,
        )

    # â”€â”€ Step C: Reporter â”€â”€
    if all_verified:
        progress_bar.progress(1.0, text="ğŸ“ ìµœì¢… ë³´ê³ ì„œ ì‘ì„± ì¤‘...")

        with st.status("ğŸ“ ìµœì¢… ë³´ê³ ì„œ ì‘ì„± ì¤‘...", expanded=True) as status:
            try:
                verified_json = json.dumps(all_verified, ensure_ascii=False, indent=2)
                final_report = call_reporter(verified_json, config)
                st.session_state.final_report = final_report
                st.session_state.analysis_log = analysis_log
                status.update(label="âœ… ë³´ê³ ì„œ ì‘ì„± ì™„ë£Œ", state="complete")
            except Exception as e:
                st.error(f"Reporter ì˜¤ë¥˜: {e}")
                status.update(label="âŒ ë³´ê³ ì„œ ì‘ì„± ì‹¤íŒ¨", state="error")
                return

        # ê²°ê³¼ í‘œì‹œ
        st.divider()
        st.markdown(final_report)
    else:
        st.warning("ê²€ì¦ì„ í†µê³¼í•œ ë°œê²¬ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

    progress_bar.empty()


def main():
    """ë©”ì¸ ì•± ì‹¤í–‰."""
    init_page()

    st.title("ğŸ” CASS Lite â€” ë²”ì£„ë¶„ì„ ì„ ë³„ ì‹œìŠ¤í…œ")
    st.caption("PDF ì¡°ì„œ â†’ AI ë¶„ì„ â†’ ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ë³´ê³ ì„œ")
    st.divider()

    # ì‚¬ì´ë“œë°” ì„¤ì •
    config = setup_sidebar()

    # ë©”ì¸ 3ë‹¨ê³„ ì›Œí¬í”Œë¡œìš°
    has_data = section_upload()
    if has_data:
        data_ready = section_review()
        if data_ready:
            section_analysis(config)


if __name__ == "__main__":
    main()
